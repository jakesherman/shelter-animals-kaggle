{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import cPickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import cross_val_score, train_test_split\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV, ParameterGrid\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab the engineered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_pickle(file_name):\n",
    "    f = open(file_name, 'rb')\n",
    "    p = cPickle.load(f)\n",
    "    f.close()\n",
    "    return p\n",
    "\n",
    "\n",
    "train = np.array(read_pickle('data/train.engineered'))\n",
    "test = np.array(read_pickle('data/test.engineered'))\n",
    "outcomes = read_pickle('data/outcomes.engineered')\n",
    "outcomes_le = read_pickle('data/outcomes_le.engineered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for nested cross-validation, model selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nested_cv(X, y, estimator, params, scoring = 'log_loss', cv = 5, \n",
    "              n_jobs = -1, verbose = True):\n",
    "    \"\"\"Performs 5-fold nested cross-validation ([cv] folds in each loop) on an \n",
    "    estimator given a parameter grid of hyperparamaters to optimize over using \n",
    "    grid search.\n",
    "    \"\"\"\n",
    "    start_time = time()\n",
    "    inner_loop = GridSearchCV(estimator, params, cv = cv, n_jobs = n_jobs, \n",
    "    scoring = scoring)\n",
    "    score = np.absolute(np.mean(cross_val_score(inner_loop, X, y, cv = cv, \n",
    "        n_jobs = 1)))\n",
    "    if verbose:\n",
    "        time_elapsed = time() - start_time\n",
    "        print 'Model:', estimator\n",
    "        print 'Score:', score\n",
    "        print 'Time elapsed:', round(time_elapsed / 60, 1), '\\n'\n",
    "    return score\n",
    "\n",
    "\n",
    "def model_selection(X, y, estimators_params, scoring = 'log_loss', cv = 5, \n",
    "                    n_jobs = -1, refit = True, higher_is_better = False, \n",
    "                    verbose = True):\n",
    "    \"\"\"Evalute multiple estimators using nested cross-validation. If refit is \n",
    "    True, the best scoring estimator is returned as part of a [cv]-fold \n",
    "    GridSearchCV estimator,such that fitting that model with X, y will find the \n",
    "    optimal hyperparameters and return a final model that can be used to make \n",
    "    predictions. [estimators_parms] is a dictionary where the key is the \n",
    "    estimator and the value is the hyperparameter grid for that estimator.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for estimator, params in estimators_params.items():\n",
    "        try:\n",
    "            score = nested_cv(X, y, estimator, params, scoring = scoring, \n",
    "                              cv = cv, n_jobs = n_jobs, verbose = verbose)\n",
    "            scores.append([score, estimator])\n",
    "        except:\n",
    "            if verbose:\n",
    "                print 'The following model failed to produced a nested-cv result:'\n",
    "                print estimator, '\\n'\n",
    "    scores = sorted(scores, reverse = higher_is_better)\n",
    "    best_model = scores[0][1]\n",
    "    if refit:\n",
    "        return GridSearchCV(best_model, estimators_params[best_model], \n",
    "                            cv = cv, n_jobs = n_jobs, scoring = scoring)\n",
    "    else:\n",
    "        return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a sense of how long different classifiers take to run one iteration. In nested-CV, each model/parameter combo will be run 25 times, then the model will be run 5 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimate_nested_cv(X, y, estimator, params = {}, \n",
    "                       outer_folds = 5, inner_folds = 5):\n",
    "    \"\"\"Estimate the time it will take to perform nested cross-validation not\n",
    "    including parallelization time.\n",
    "    \"\"\"\n",
    "    outer_fold_samples = X.shape[0] * ((outer_folds - 1) / outer_folds)\n",
    "    inner_fold_samples = outer_fold_samples * ((inner_folds - 1) / inner_folds)\n",
    "    num_params = len(ParameterGrid(params))\n",
    "    \n",
    "    # Time an inner fold\n",
    "    inner_start = time()\n",
    "    estimator.fit(X[:inner_fold_samples, :], y[:inner_fold_samples])\n",
    "    inner_time = time() - inner_start\n",
    "    inner_times = inner_time * outer_folds * inner_folds * num_params\n",
    "    \n",
    "    # Time an outer fold\n",
    "    outer_start = time()\n",
    "    estimator.fit(X[:outer_fold_samples, :], y[:outer_fold_samples])\n",
    "    outer_time = time() - outer_start\n",
    "    outer_times = outer_time * outer_folds\n",
    "    \n",
    "    return (inner_times + outer_times) / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jake/miniconda2/envs/shelter-animals/lib/python2.7/site-packages/ipykernel/__main__.py:12: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/jake/miniconda2/envs/shelter-animals/lib/python2.7/site-packages/ipykernel/__main__.py:18: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.366394241650899"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_nested_cv(train, outcomes, LogisticRegression(random_state = 50), params = {\n",
    "            'penalty': ['l1', 'l2'], \n",
    "            'class_weight': [None, 'balanced'],\n",
    "            'C': np.logspace(-3, 3, 7)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try a bunch of different classifiers, from a baseline model like logistic regression all the way up to a model we expect to perform well like random forests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ParameterGrid({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ParameterGrid({\n",
    "            'penalty': ['l1', 'l2'], \n",
    "            'class_weight': [None, 'balanced'],\n",
    "            'C': np.logspace(-3, 3, 7)\n",
    "    }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jake/miniconda2/envs/shelter-animals/lib/python2.7/site-packages/sklearn/grid_search.py:418: ChangedBehaviorWarning: The long-standing behavior to use the estimator's score function in GridSearchCV.score has changed. The scoring parameter is now used.\n",
      "  ChangedBehaviorWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=50, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Score: 0.890816563039\n",
      "Time elapsed: 23.9 \n",
      "\n",
      "CPU times: user 40.3 s, sys: 852 ms, total: 41.2 s\n",
      "Wall time: 23min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "estimators_params = {\n",
    "    \n",
    "    # Logistic regression, good baseline model\n",
    "    LogisticRegression(random_state = 50) :  {\n",
    "            'penalty': ['l1', 'l2'], \n",
    "            'class_weight': [None, 'balanced'],\n",
    "            'C': np.logspace(-3, 3, 7)\n",
    "    }\n",
    "}\n",
    "\n",
    "model_selection(train, outcomes, estimators_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "estimators_params = {\n",
    "    \n",
    "    # Logistic regression, good baseline model\n",
    "    LogisticRegression(random_state = 50) :  {\n",
    "            'penalty': ['l1', 'l2'], \n",
    "            'class_weight': [None, 'balanced'],\n",
    "            'C': np.logspace(-3, 3, 7)\n",
    "    },\n",
    "    \n",
    "    # SGD logsitic regression w/ elastic net regularization - likely won't perform\n",
    "    # as well as LR b/c it's using SGD, but I want to see if elasticnet helps\n",
    "    SGDClassifier(random_state = 50, loss = 'log', penalty = 'elasticnet') : {\n",
    "            'alpha': np.logspace(-3, 3, 7)\n",
    "    },\n",
    "    \n",
    "    # SVM w/ a linear kernel - LinearSVC is faster than SVC for this kernel\n",
    "    LinearSVC(random_state = 50) : {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'class_weight': [None, 'balanced'],\n",
    "        'C': np.logspace(-3, 3, 7)\n",
    "    },\n",
    "    \n",
    "    # SVM w/ RBF kernel\n",
    "    SVC(random_state = 25, probability = True, kernel = 'rbf') : {\n",
    "        'C': np.logspace(-3, 3, 7), \n",
    "        'gamma': np.logspace(-6, 3, 10), \n",
    "        'class_weight' : [None, 'balanced']\n",
    "    },\n",
    "    \n",
    "    # SVM w/ polynomial kernel\n",
    "    SVC(random_state = 25, probability = True, kernel = 'poly') : {\n",
    "        'C': np.logspace(-3, 3, 7), \n",
    "        'degree': [2, 3, 4, 5], \n",
    "        'coef0': [0, 1],\n",
    "        'class_weight' : [None, 'balanced']\n",
    "    },\n",
    "    \n",
    "    # Random forest, others in this challenge have had success w/ this algorithm\n",
    "    RandomForestClassifier(random_state = 25, n_estimators = 1000) : {\n",
    "        'max_features' : ['sqrt', 'log2'],\n",
    "        'max_depth' : [3, None],\n",
    "        'min_samples_split': [1, 2, 3, 7],\n",
    "        'min_samples_leaf': [1, 3, 7],\n",
    "        'class_weight' : [None, 'balanced']\n",
    "    },\n",
    "    \n",
    "    # ExtraTreesClassifier - using same params as the random forest\n",
    "    ExtraTreesClassifier(random_state = 25, n_estimators = 1000) : {\n",
    "        'max_features' : ['sqrt', 'log2'],\n",
    "        'max_depth' : [3, None],\n",
    "        'min_samples_split': [1, 2, 3, 7],\n",
    "        'min_samples_leaf': [1, 3, 7],\n",
    "        'class_weight' : [None, 'balanced']\n",
    "    }\n",
    "}\n",
    "\n",
    "best_performing_model = model_selection(train, outcomes, estimators_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
